{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "sys.path.append('../src/')\n",
    "from scraper.scraper import Scraper\n",
    "from results.results import Results\n",
    "from database.create_db import Database\n",
    "from database.database import Event, Race, Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db: Database = Database.create_database(path='../data/parsed_data.db')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = Scraper()\n",
    "events = scraper.getEvents()\n",
    "years = scraper.getEventsYears()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of events and years\n",
    "events = dict(sorted(scraper.getEvents().items(), key=lambda item: item[1]))\n",
    "# Remove years and strip\n",
    "events = {key: ' '.join(word for word in value.split() if not word.isdigit() or len(word) != 4).strip() for key, value in events.items()}\n",
    "events = {key: re.sub(r'^\\d{4}|\\d{4}$', '', value).strip() for key, value in events.items()}\n",
    "# Remove French ordinals\n",
    "events = {key: re.sub(r'(\\d{1,2}(?:e|Ã¨me))', '', value).strip() for key, value in events.items()}\n",
    "# Remove HTML tags\n",
    "events = {key: re.sub(r'<[^<]+?>', '', value).strip() for key, value in events.items()}\n",
    "# Sort alphabetically\n",
    "events = dict(sorted(events.items(), key=lambda item: item[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code, name in events.items():\n",
    "    if code in years:\n",
    "        for year in years[code]: \n",
    "            event = Event(event_code=code,\n",
    "                        event_name=name,\n",
    "                        year=year,\n",
    "                        country=None,\n",
    "                        db=db)\n",
    "            event.save_to_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to resume from a partial download\n",
    "def parse_done_txt_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        parsed_data = {}\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2:\n",
    "                race_name = parts[0]\n",
    "                years = [year for year in parts[1:]]\n",
    "                parsed_data.setdefault(race_name, []).extend(years)\n",
    "    return parsed_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to skip races, create a text file `output_parsing.txt` containing one code and year per line wanting to be ignored, for example:\n",
    "\n",
    "```\n",
    "saintelyon 2018\n",
    "saintelyon 2017\n",
    "saintelyon 2016\n",
    "saintelyon 2015\n",
    "saintelyon 2014\n",
    "saintelyon 2013\n",
    "penyagolosa 2024\n",
    "penyagolosa 2023\n",
    "penyagolosa 2022\n",
    "penyagolosa 2021\n",
    "penyagolosa 2019\n",
    "# lut 2016 -> parcours.php is empty\n",
    "lut 2016\n",
    "# oxfamtrailwalkerhk 2021 -> Password protected\n",
    "oxfamtrailwalkerhk 2021\n",
    "```\n",
    "\n",
    "If you interrupt the execution, copy the output of the next cell in the file and races already parsed will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_races = parse_done_txt_file('output_parsing.txt')\n",
    "for event, name in events.items():\n",
    "    if event in years:\n",
    "        for year in years[event]:\n",
    "            if event in parsed_races:\n",
    "                if year in parsed_races[event]:\n",
    "                    continue\n",
    "            print(event, year)\n",
    "            scraper.setEvents([event])\n",
    "            scraper.setYears([year])\n",
    "            cps = scraper.getControlPoints()\n",
    "            if not cps:\n",
    "                continue\n",
    "            races = scraper.getRaces()\n",
    "            rr = scraper.getRandomRunnerBib()\n",
    "            scraper.downloadData()\n",
    "            races_data = scraper.getRacesPhysicalDetails()\n",
    "            if event not in races:\n",
    "                #st.write(f'No data available for {events[event]} {year}. Please select another event.')\n",
    "                pass\n",
    "            elif year not in races[event]:\n",
    "                #st.write(f'No data available for {events[event]} {year}. Please select another event or year.')\n",
    "                pass\n",
    "            else:\n",
    "                races = races[event][year]\n",
    "                for code, name in races.items():\n",
    "                    if code not in cps:\n",
    "                        continue\n",
    "                    if code=='maxirace' and 'Orientation' in name:\n",
    "                        # 'maxirace' has two orientation races not standard\n",
    "                        continue\n",
    "                    elif name.lower()=='course des partenaires':\n",
    "                        continue\n",
    "                    event_id= Event.get_id_from_code_year(event, year, db)\n",
    "                    scraper.setRace(code)\n",
    "                    folder_path = f'data/{event}'\n",
    "                    filepath = os.path.join(folder_path, f'{event}_{code}_{year}.csv')\n",
    "                    results_filepath = filepath if os.path.exists(os.path.join('../../',filepath)) else None\n",
    "                    race_info = scraper.getRaceInfo(bibN=rr[year][code]) if rr[year][code] is not None else {'date':None, 'hd':None}\n",
    "                    control_points = cps[code]\n",
    "                    race_data = races_data[code]\n",
    "                    if race_info: # some races are empty but have empty rows in data (e.g. 'templiers', 'Templi', 2019)\n",
    "                        departure_datetime=' '.join([race_info['date'], race_info['hd']]) if race_info['date'] else None\n",
    "                    else:\n",
    "                        departure_datetime = None\n",
    "                    r = Race(race_id=code, event_id=event_id, race_name=name, distance=race_data['distance'],\n",
    "                    elevation_pos=race_data['elevation_pos'], elevation_neg=race_data['elevation_pos'], departure_datetime=departure_datetime,\n",
    "                    results_filepath=results_filepath, db=db)\n",
    "                    r.save_to_database()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO-DO in this notebook\n",
    "\n",
    "- [ ] Load CSV results to DB"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
